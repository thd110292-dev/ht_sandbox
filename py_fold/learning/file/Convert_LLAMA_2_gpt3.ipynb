{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cfa9090-2aa6-455b-99b5-5bd792c1a185",
   "metadata": {},
   "source": [
    "# Convert LLAMA model to gpt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2366bbcb-3984-476a-8ddd-c47a91dfac1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nbformat\n",
      "  Downloading nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat)\n",
      "  Downloading fastjsonschema-2.21.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting jsonschema>=2.6 (from nbformat)\n",
      "  Downloading jsonschema-4.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\justa\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from nbformat) (5.9.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\justa\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from nbformat) (5.14.3)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=2.6->nbformat)\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=2.6->nbformat)\n",
      "  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=2.6->nbformat)\n",
      "  Downloading referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.25.0 (from jsonschema>=2.6->nbformat)\n",
      "  Downloading rpds_py-0.30.0-cp310-cp310-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\justa\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in c:\\users\\justa\\anaconda3\\envs\\pytorch_env\\lib\\site-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat) (4.15.0)\n",
      "Downloading nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Downloading fastjsonschema-2.21.2-py3-none-any.whl (24 kB)\n",
      "Downloading jsonschema-4.26.0-py3-none-any.whl (90 kB)\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Downloading referencing-0.37.0-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.30.0-cp310-cp310-win_amd64.whl (235 kB)\n",
      "Installing collected packages: fastjsonschema, rpds-py, attrs, referencing, jsonschema-specifications, jsonschema, nbformat\n",
      "\n",
      "   ---------------------- ----------------- 4/7 [jsonschema-specifications]\n",
      "   ---------------------------------- ----- 6/7 [nbformat]\n",
      "   ---------------------------------------- 7/7 [nbformat]\n",
      "\n",
      "Successfully installed attrs-25.4.0 fastjsonschema-2.21.2 jsonschema-4.26.0 jsonschema-specifications-2025.9.1 nbformat-5.10.4 referencing-0.37.0 rpds-py-0.30.0\n"
     ]
    }
   ],
   "source": [
    "!pip install nbformat\n",
    "# !pip install blobfile\n",
    "# !pip install huggingface_hub\n",
    "# !pip install matplotlib\n",
    "# !pip install tiktoken\n",
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5030c269-3bfa-46ec-8273-e64d054d79ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "# pkgs = [\n",
    "#     \"blobfile\",         # to download pretrained weights\n",
    "#     \"huggingface_hub\",  # to download pretrained weights\n",
    "#     \"matplotlib\",       # to visualize RoPE with different base frequencies\n",
    "#     \"tiktoken\",         # to implement the tokenizer\n",
    "#     \"torch\",            # to implement the model\n",
    "# ]\n",
    "# for p in pkgs:\n",
    "#     print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56e49375-fb03-4d2d-9eeb-af9475d665f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Notebook file not found at: C:\\Users\\justa\\Downloads\\dataset\\converting-gpt-to-llama2.ipynb",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 40\u001b[0m\n\u001b[0;32m     36\u001b[0m     names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecompute_rope_params\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompute_rope\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSiLU\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeedForward\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSNorm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiHeadAttention\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m import_definitions_from_notebook(fullname, names)\n\u001b[1;32m---> 40\u001b[0m imported_module \u001b[38;5;241m=\u001b[39m \u001b[43mimport_from_notebook\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# We need to redefine precompute_rope_params\u001b[39;00m\n\u001b[0;32m     43\u001b[0m precompute_rope_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(imported_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecompute_rope_params\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[11], line 38\u001b[0m, in \u001b[0;36mimport_from_notebook\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m fullname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconverting-gpt-to-llama2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     36\u001b[0m names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecompute_rope_params\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompute_rope\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSiLU\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeedForward\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSNorm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiHeadAttention\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimport_definitions_from_notebook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 16\u001b[0m, in \u001b[0;36mimport_from_notebook.<locals>.import_definitions_from_notebook\u001b[1;34m(fullname, names)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Load the notebook\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(path):\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNotebook file not found at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m io\u001b[38;5;241m.\u001b[39mopen(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     19\u001b[0m     nb \u001b[38;5;241m=\u001b[39m nbformat\u001b[38;5;241m.\u001b[39mread(f, as_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Notebook file not found at: C:\\Users\\justa\\Downloads\\dataset\\converting-gpt-to-llama2.ipynb"
     ]
    }
   ],
   "source": [
    "# load LLama2 component\n",
    "import os\n",
    "import sys\n",
    "import io\n",
    "import nbformat\n",
    "import types\n",
    "\n",
    "def import_from_notebook():\n",
    "    def import_definitions_from_notebook(fullname, names):\n",
    "        current_dir = os.getcwd()\n",
    "        path = os.path.join(current_dir, fullname + \".ipynb\")\n",
    "        path = os.path.normpath(path)\n",
    "\n",
    "        # Load the notebook\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(f\"Notebook file not found at: {path}\")\n",
    "\n",
    "        with io.open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "        # Create a module to store the imported functions and classes\n",
    "        mod = types.ModuleType(fullname)\n",
    "        sys.modules[fullname] = mod\n",
    "\n",
    "        # Go through the notebook cells and only execute function or class definitions\n",
    "        for cell in nb.cells:\n",
    "            if cell.cell_type == \"code\":\n",
    "                cell_code = cell.source\n",
    "                for name in names:\n",
    "                    # Check for function or class definitions\n",
    "                    if f\"def {name}\" in cell_code or f\"class {name}\" in cell_code:\n",
    "                        exec(cell_code, mod.__dict__)\n",
    "        return mod\n",
    "\n",
    "    fullname = \"converting-gpt-to-llama2\"\n",
    "    names = [\"precompute_rope_params\", \"compute_rope\", \"SiLU\", \"FeedForward\", \"RMSNorm\", \"MultiHeadAttention\"]\n",
    "\n",
    "    return import_definitions_from_notebook(fullname, names)\n",
    "\n",
    "imported_module = import_from_notebook()\n",
    "\n",
    "# We need to redefine precompute_rope_params\n",
    "precompute_rope_params = getattr(imported_module, \"precompute_rope_params\", None)\n",
    "compute_rope = getattr(imported_module, \"compute_rope\", None)\n",
    "SiLU = getattr(imported_module, \"SiLU\", None)\n",
    "FeedForward = getattr(imported_module, \"FeedForward\", None)\n",
    "RMSNorm = getattr(imported_module, \"RMSNorm\", None)\n",
    "\n",
    "# MultiHeadAttention only for comparison purposes\n",
    "MultiHeadAttention = getattr(imported_module, \"MultiHeadAttention\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2809142-808c-4229-8527-c4890749b467",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-pytorch_env]",
   "language": "python",
   "name": "conda-env-anaconda3-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
